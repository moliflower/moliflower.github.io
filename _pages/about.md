---
layout: about
title: about
permalink: /
subtitle: <a href='#'>Intelligent Computing Laboratory</a>. Shanghai University. Yuhan Deng. Efficient LLM Inference.

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <p>Room 502, Intelligent Computing Lab</p>
    <p>Shanghai University , Shanghai</p>
    <p>Emailï¼š18870788548@shu.edu.cn</p>

selected_papers: false # includes a list of papers marked as "selected={true}"
social: false # includes social icons at the bottom of the page

announcements:
  enabled: true # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: true
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---

Hi, I'm **Yuhan Deng**, a master's student at XXX University and a member of the **Intelligent Computing Laboratory (ICL)**.  

My research focuses on **efficient inference techniques for large language models**, including system-level optimization, CUDA kernel acceleration, FlashAttention, and model quantization.  

I am passionate about **high-performance AI systems** and making large-scale models faster and more memory-efficient.  

You can reach me at: **18870788548@shu.edu.cn**  

Connect with me:  
[![GitHub](https://img.shields.io/badge/GitHub-%2312100E.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/moliflower)  

